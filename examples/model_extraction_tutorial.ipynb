{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef48374d",
   "metadata": {},
   "source": [
    "# AI Model Extraction Simulator\n",
    "## Makine Öğrenimi Modeli Çalma Simülatörü\n",
    "\n",
    "Bu notebook, makine öğrenimi modellerinin siyah kutu (black-box) saldırılarla nasıl çalınabileceğini simüle eder.\n",
    "\n",
    "⚠️ **Etik Uyarı**: Bu araç yalnızca eğitim ve güvenlik araştırması amaçlıdır. Gerçek sistemlere karşı izinsiz kullanımı yasaktır.\n",
    "\n",
    "## Çalışma Prensibi\n",
    "```\n",
    "Saldırgan → API Sorguları → Kurban Model → Yanıtlar → Transfer Öğrenme → Klon Model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kütüphaneleri import et\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Proje kök dizinini ekle\n",
    "project_root = Path.cwd().parent if 'examples' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Proje modülleri\n",
    "from src.victim_model.victim_model import VictimModel, VictimModelAPI\n",
    "from src.attacker.extraction_strategies import (\n",
    "    RandomQueryStrategy, ActiveLearningStrategy, AdversarialQueryStrategy,\n",
    "    ModelExtractor\n",
    ")\n",
    "from src.clone_model.clone_model import CloneModel\n",
    "from src.utils.utils import (\n",
    "    get_device, set_random_seeds, calculate_model_similarity,\n",
    "    evaluate_model_performance, count_parameters\n",
    ")\n",
    "\n",
    "# Ayarlar\n",
    "plt.style.use('seaborn-v0_8')\n",
    "device = get_device()\n",
    "set_random_seeds(42)\n",
    "\n",
    "print(f\"🚀 AI Model Extraction Simulator\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d303005",
   "metadata": {},
   "source": [
    "## 1. Kurban Model Oluşturma\n",
    "\n",
    "İlk olarak, çalmaya çalışacağımız kurban modeli oluşturalım. Bu model gerçek dünyada korumalı bir API arkasında olacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008412e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurban modeli oluştur\n",
    "print(\"📦 Creating victim model...\")\n",
    "victim_model = VictimModel(\n",
    "    model_type=\"resnet18\",\n",
    "    num_classes=10,  # CIFAR-10 için\n",
    "    pretrained=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# API wrapper oluştur\n",
    "victim_api = VictimModelAPI(victim_model, rate_limit=None)\n",
    "\n",
    "# Model bilgilerini göster\n",
    "param_count = count_parameters(victim_model.model)\n",
    "print(f\"✅ Victim model created\")\n",
    "print(f\"📊 Parameters: {param_count:,}\")\n",
    "print(f\"📊 Model type: {victim_model.model_type}\")\n",
    "print(f\"📊 Classes: {victim_model.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319cffe",
   "metadata": {},
   "source": [
    "## 2. Kurban Modeli Test Etme\n",
    "\n",
    "Kurban modelinin çalıştığından emin olalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a696eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verisi oluştur\n",
    "test_input = torch.randn(5, 3, 32, 32)  # 5 rastgele görüntü\n",
    "\n",
    "# Kurban modeli sorgula\n",
    "victim_response = victim_model.query(test_input, return_logits=True)\n",
    "\n",
    "print(\"🧪 Victim model test:\")\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Predictions: {victim_response['predictions']}\")\n",
    "print(f\"Confidence scores: {victim_response['confidence']}\")\n",
    "print(f\"Query count: {victim_model.query_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a56de",
   "metadata": {},
   "source": [
    "## 3. Farklı Saldırı Stratejileri\n",
    "\n",
    "Şimdi farklı sorgulama stratejilerini test edelim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b81877",
   "metadata": {},
   "source": [
    "### 3.1 Rastgele Sorgulama Stratejisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastgele sorgulama stratejisi\n",
    "print(\"🎲 Testing Random Query Strategy\")\n",
    "\n",
    "random_strategy = RandomQueryStrategy(\n",
    "    data_distribution=\"uniform\",\n",
    "    input_shape=(3, 32, 32)\n",
    ")\n",
    "\n",
    "# Örnek sorgular oluştur\n",
    "random_queries = random_strategy.select_queries(budget=100)\n",
    "print(f\"Generated {len(random_queries)} random queries\")\n",
    "print(f\"Query shape: {random_queries.shape}\")\n",
    "print(f\"Value range: [{random_queries.min():.3f}, {random_queries.max():.3f}]\")\n",
    "\n",
    "# İlk birkaç sorguyu görselleştir\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i in range(4):\n",
    "    # Channels first'ten channels last'e çevir\n",
    "    img = random_queries[i].transpose(1, 2, 0)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Random Query {i+1}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992829a3",
   "metadata": {},
   "source": [
    "### 3.2 Aktif Öğrenme Stratejisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745302f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktif öğrenme stratejisi\n",
    "print(\"🧠 Testing Active Learning Strategy\")\n",
    "\n",
    "active_strategy = ActiveLearningStrategy(\n",
    "    initial_pool_size=500,\n",
    "    uncertainty_method=\"entropy\"\n",
    ")\n",
    "\n",
    "# İlk sorgular (clone model olmadan)\n",
    "active_queries = active_strategy.select_queries(budget=50)\n",
    "print(f\"Generated {len(active_queries)} active learning queries\")\n",
    "print(f\"Strategy uses uncertainty-based selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810c798",
   "metadata": {},
   "source": [
    "## 4. Model Çıkarma Süreci\n",
    "\n",
    "Şimdi gerçek model çıkarma sürecini başlatalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model extractor oluştur\n",
    "print(\"🔓 Setting up model extractor\")\n",
    "\n",
    "# Rastgele strateji ile başla (daha hızlı demo için)\n",
    "extractor = ModelExtractor(\n",
    "    query_strategy=random_strategy,\n",
    "    victim_api=victim_api,\n",
    "    query_budget=2000  # Küçük budget (notebook için)\n",
    ")\n",
    "\n",
    "print(f\"✅ Extractor ready with budget: {extractor.query_budget:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilgi çıkarma\n",
    "print(\"🕳️ Extracting knowledge from victim model...\")\n",
    "\n",
    "stolen_queries, stolen_responses = extractor.extract_knowledge(batch_size=64)\n",
    "\n",
    "# İstatistikleri göster\n",
    "extraction_stats = extractor.get_extraction_statistics()\n",
    "print(f\"\\n📊 Extraction Statistics:\")\n",
    "for key, value in extraction_stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\n✅ Collected {len(stolen_queries):,} query-response pairs\")\n",
    "print(f\"📊 Data shape: {stolen_queries.shape} → {stolen_responses.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d9786",
   "metadata": {},
   "source": [
    "## 5. Klon Model Oluşturma ve Eğitimi\n",
    "\n",
    "Çalınan verilerle klon modeli eğitelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72264096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klon model oluştur\n",
    "print(\"🤖 Creating clone model\")\n",
    "\n",
    "clone_model = CloneModel(\n",
    "    architecture=\"simple_cnn\",  # Daha basit mimari\n",
    "    num_classes=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "clone_params = count_parameters(clone_model.model)\n",
    "print(f\"✅ Clone model created\")\n",
    "print(f\"📊 Parameters: {clone_params:,}\")\n",
    "print(f\"📊 Architecture: {clone_model.architecture}\")\n",
    "print(f\"📊 Victim vs Clone ratio: {clone_params/param_count:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klon model eğitimi\n",
    "print(\"🎓 Training clone model with stolen data...\")\n",
    "\n",
    "training_results = clone_model.train_with_stolen_data(\n",
    "    stolen_queries=stolen_queries,\n",
    "    stolen_labels=stolen_responses,\n",
    "    epochs=30,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "    temperature=3.0\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Training completed!\")\n",
    "print(f\"📈 Final loss: {training_results['final_loss']:.4f}\")\n",
    "print(f\"📈 Final accuracy: {training_results['final_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf49893",
   "metadata": {},
   "source": [
    "## 6. Eğitim Görselleştirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33480257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eğitim geçmişini görselleştir\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss grafiği\n",
    "axes[0].plot(training_results['training_losses'])\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy grafiği\n",
    "axes[1].plot(training_results['training_accuracies'])\n",
    "axes[1].set_title('Training Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea460094",
   "metadata": {},
   "source": [
    "## 7. Model Değerlendirmesi ve Karşılaştırma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verisi oluştur\n",
    "print(\"🧪 Evaluating models...\")\n",
    "\n",
    "test_size = 500\n",
    "test_queries = np.random.uniform(0, 1, (test_size, 3, 32, 32)).astype(np.float32)\n",
    "test_tensor = torch.from_numpy(test_queries)\n",
    "\n",
    "# Her iki modelden tahmin al\n",
    "print(\"Getting predictions from victim model...\")\n",
    "victim_predictions = victim_model.query(test_tensor)\n",
    "\n",
    "print(\"Getting predictions from clone model...\")\n",
    "clone_predictions = clone_model.predict(test_tensor)\n",
    "\n",
    "# Benzerlik metriklerini hesapla\n",
    "similarity_metrics = calculate_model_similarity(\n",
    "    victim_predictions['probabilities'], \n",
    "    clone_predictions['probabilities']\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Model Similarity Metrics:\")\n",
    "for key, value in similarity_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78c8a5",
   "metadata": {},
   "source": [
    "## 8. Detaylı Analiz ve Görselleştirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3998386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin dağılımlarını karşılaştır\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Fidelity analizi\n",
    "victim_pred_labels = victim_predictions['predictions']\n",
    "clone_pred_labels = clone_predictions['predictions']\n",
    "agreement = victim_pred_labels == clone_pred_labels\n",
    "\n",
    "axes[0, 0].hist([victim_pred_labels, clone_pred_labels], bins=10, alpha=0.7, \n",
    "                label=['Victim', 'Clone'])\n",
    "axes[0, 0].set_title('Prediction Distribution')\n",
    "axes[0, 0].set_xlabel('Class')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Agreement analizi\n",
    "axes[0, 1].pie([agreement.sum(), (~agreement).sum()], \n",
    "               labels=['Agreement', 'Disagreement'],\n",
    "               autopct='%1.1f%%',\n",
    "               colors=['lightgreen', 'lightcoral'])\n",
    "axes[0, 1].set_title(f'Model Agreement (Fidelity: {similarity_metrics[\"fidelity\"]:.2%})')\n",
    "\n",
    "# Confidence karşılaştırması\n",
    "victim_conf = victim_predictions['confidence']\n",
    "clone_conf = clone_predictions['probabilities'].max(axis=1)\n",
    "\n",
    "axes[1, 0].scatter(victim_conf, clone_conf, alpha=0.5)\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Victim Confidence')\n",
    "axes[1, 0].set_ylabel('Clone Confidence')\n",
    "axes[1, 0].set_title('Confidence Correlation')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Query efficiency\n",
    "query_efficiency = similarity_metrics['fidelity'] / extractor.query_count * 1000\n",
    "metrics_data = {\n",
    "    'Fidelity': similarity_metrics['fidelity'],\n",
    "    'Cosine Sim': similarity_metrics['cosine_similarity'],\n",
    "    'Query Eff.\\n(×1000)': query_efficiency\n",
    "}\n",
    "\n",
    "bars = axes[1, 1].bar(metrics_data.keys(), metrics_data.values(), \n",
    "                      color=['skyblue', 'lightgreen', 'orange'])\n",
    "axes[1, 1].set_title('Performance Metrics')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "\n",
    "# Bar değerlerini ekle\n",
    "for bar, value in zip(bars, metrics_data.values()):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffde10",
   "metadata": {},
   "source": [
    "## 9. Farklı Stratejilerin Karşılaştırması\n",
    "\n",
    "Şimdi farklı sorgulama stratejilerinin performansını karşılaştıralım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9af196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farklı stratejileri test et\n",
    "def test_strategy(strategy_name, strategy, budget=1000):\n",
    "    \"\"\"Bir stratejiyi test et\"\"\"\n",
    "    print(f\"\\n🧪 Testing {strategy_name} strategy...\")\n",
    "    \n",
    "    # Kurban model sorgularını sıfırla\n",
    "    victim_model.reset_query_log()\n",
    "    \n",
    "    # Extractor oluştur\n",
    "    extractor = ModelExtractor(\n",
    "        query_strategy=strategy,\n",
    "        victim_api=victim_api,\n",
    "        query_budget=budget\n",
    "    )\n",
    "    \n",
    "    # Bilgi çıkar\n",
    "    queries, responses = extractor.extract_knowledge(batch_size=32)\n",
    "    \n",
    "    # Basit clone model eğit\n",
    "    clone = CloneModel(\"lightweight\", 10, device)\n",
    "    training_results = clone.train_with_stolen_data(\n",
    "        queries, responses, epochs=15, learning_rate=0.01\n",
    "    )\n",
    "    \n",
    "    # Test et\n",
    "    test_inputs = torch.randn(200, 3, 32, 32)\n",
    "    victim_out = victim_model.query(test_inputs)['probabilities']\n",
    "    clone_out = clone.predict(test_inputs)['probabilities']\n",
    "    \n",
    "    similarity = calculate_model_similarity(victim_out, clone_out)\n",
    "    \n",
    "    return {\n",
    "        'fidelity': similarity['fidelity'],\n",
    "        'queries_used': extractor.query_count,\n",
    "        'final_loss': training_results['final_loss'],\n",
    "        'query_efficiency': similarity['fidelity'] / extractor.query_count * 1000\n",
    "    }\n",
    "\n",
    "# Stratejileri test et\n",
    "strategies = {\n",
    "    'Random (Uniform)': RandomQueryStrategy(\"uniform\", (3, 32, 32)),\n",
    "    'Random (Normal)': RandomQueryStrategy(\"normal\", (3, 32, 32)),\n",
    "    'Active Learning': ActiveLearningStrategy(500, \"entropy\")\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, strategy in strategies.items():\n",
    "    results[name] = test_strategy(name, strategy, budget=800)\n",
    "\n",
    "print(\"\\n📊 Strategy Comparison Results:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for metric, value in result.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strateji karşılaştırması görselleştirmesi\n",
    "metrics = ['fidelity', 'query_efficiency', 'final_loss']\n",
    "strategy_names = list(results.keys())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [results[name][metric] for name in strategy_names]\n",
    "    \n",
    "    bars = axes[i].bar(strategy_names, values, color=['skyblue', 'lightgreen', 'orange'])\n",
    "    axes[i].set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_ylabel('Score' if metric != 'final_loss' else 'Loss')\n",
    "    \n",
    "    # Değerleri bar üzerine yaz\n",
    "    for bar, value in zip(bars, values):\n",
    "        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # X eksenindeki isimleri döndür\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637088f",
   "metadata": {},
   "source": [
    "## 10. Güvenlik İmplications ve Savunma Yöntemleri\n",
    "\n",
    "Bu bölümde model çalma saldırılarına karşı savunma yöntemlerini tartışalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savunma yöntemlerini simüle et\n",
    "def test_defense_mechanism(defense_name, defense_func):\n",
    "    \"\"\"Savunma mekanizması test et\"\"\"\n",
    "    print(f\"\\n🛡️ Testing {defense_name}...\")\n",
    "    \n",
    "    # Savunmalı kurban model oluştur\n",
    "    defended_model = VictimModel(\"resnet18\", 10, True, device)\n",
    "    \n",
    "    # Savunma fonksiyonunu uygula\n",
    "    defended_api = defense_func(defended_model)\n",
    "    \n",
    "    # Saldırıyı dene\n",
    "    extractor = ModelExtractor(\n",
    "        RandomQueryStrategy(\"uniform\", (3, 32, 32)),\n",
    "        defended_api,\n",
    "        query_budget=500\n",
    "    )\n",
    "    \n",
    "    queries, responses = extractor.extract_knowledge()\n",
    "    \n",
    "    # Klon model eğit\n",
    "    clone = CloneModel(\"lightweight\", 10, device)\n",
    "    clone.train_with_stolen_data(queries, responses, epochs=10)\n",
    "    \n",
    "    # Değerlendir\n",
    "    test_inputs = torch.randn(100, 3, 32, 32)\n",
    "    original_out = defended_model.query(test_inputs)['probabilities']\n",
    "    clone_out = clone.predict(test_inputs)['probabilities']\n",
    "    \n",
    "    similarity = calculate_model_similarity(original_out, clone_out)\n",
    "    return similarity['fidelity']\n",
    "\n",
    "# Savunma mekanizmaları\n",
    "def rate_limiting_defense(victim_model):\n",
    "    \"\"\"Rate limiting savunması\"\"\"\n",
    "    return VictimModelAPI(victim_model, rate_limit=100)\n",
    "\n",
    "def noise_defense(victim_model):\n",
    "    \"\"\"Noise ekleme savunması\"\"\"\n",
    "    class NoisyAPI(VictimModelAPI):\n",
    "        def predict(self, image_data, return_probabilities=True):\n",
    "            # Tahminlere noise ekle\n",
    "            result = super().predict(image_data, return_probabilities)\n",
    "            if 'probabilities' in result:\n",
    "                probs = np.array(result['probabilities'])\n",
    "                noise = np.random.normal(0, 0.05, probs.shape)\n",
    "                noisy_probs = probs + noise\n",
    "                # Normalize et\n",
    "                noisy_probs = np.maximum(noisy_probs, 0)\n",
    "                noisy_probs = noisy_probs / noisy_probs.sum(axis=-1, keepdims=True)\n",
    "                result['probabilities'] = noisy_probs.tolist()\n",
    "            return result\n",
    "    return NoisyAPI(victim_model)\n",
    "\n",
    "# Savunmaları test et\n",
    "defenses = {\n",
    "    'No Defense': lambda vm: VictimModelAPI(vm),\n",
    "    'Rate Limiting': rate_limiting_defense,\n",
    "    'Output Noise': noise_defense\n",
    "}\n",
    "\n",
    "defense_results = {}\n",
    "for name, defense in defenses.items():\n",
    "    fidelity = test_defense_mechanism(name, defense)\n",
    "    defense_results[name] = fidelity\n",
    "    print(f\"  Fidelity: {fidelity:.4f}\")\n",
    "\n",
    "print(\"\\n🛡️ Defense Effectiveness:\")\n",
    "for name, fidelity in defense_results.items():\n",
    "    print(f\"  {name}: {fidelity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savunma etkinliği görselleştirmesi\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "defense_names = list(defense_results.keys())\n",
    "fidelities = list(defense_results.values())\n",
    "\n",
    "bars = plt.bar(defense_names, fidelities, color=['red', 'orange', 'green'])\n",
    "plt.title('Defense Mechanism Effectiveness\\n(Lower Fidelity = Better Defense)')\n",
    "plt.ylabel('Attack Fidelity')\n",
    "plt.xlabel('Defense Method')\n",
    "\n",
    "# Değerleri bar üzerine yaz\n",
    "for bar, value in zip(bars, fidelities):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c8fc5f",
   "metadata": {},
   "source": [
    "## 11. Sonuçlar ve Öneriler\n",
    "\n",
    "### Ana Bulgular:\n",
    "\n",
    "1. **Model Extraction Feasibility**: Siyah kutu modelleri bile çalınabilir\n",
    "2. **Query Efficiency**: Farklı stratejiler farklı verimlilik seviyeleri gösterir\n",
    "3. **Defense Mechanisms**: Basit savunma yöntemleri bile etkili olabilir\n",
    "\n",
    "### Güvenlik Önerileri:\n",
    "\n",
    "1. **Rate Limiting**: API çağrı limitleri koyun\n",
    "2. **Output Perturbation**: Çıktılara kontrollü noise ekleyin\n",
    "3. **Query Monitoring**: Anormal sorgu patternlerini izleyin\n",
    "4. **Differential Privacy**: Gizlilik koruyucu teknikler kullanın\n",
    "5. **Watermarking**: Model watermark'ları ekleyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final özet\n",
    "print(\"📋 Experiment Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"🎯 Original victim model accuracy: High (pretrained)\")\n",
    "print(f\"🤖 Clone model achieved: {similarity_metrics['fidelity']:.2%} fidelity\")\n",
    "print(f\"📊 Query budget used: {extractor.query_count:,}\")\n",
    "print(f\"⚡ Query efficiency: {query_efficiency:.4f} (fidelity per 1000 queries)\")\n",
    "print(f\"🛡️ Defense effectiveness: Noise injection reduced fidelity by {defense_results['No Defense'] - defense_results['Output Noise']:.2%}\")\n",
    "\n",
    "print(\"\\n⚠️ Ethical Reminder:\")\n",
    "print(\"This simulation is for educational purposes only.\")\n",
    "print(\"Real-world model extraction attacks are illegal without permission.\")\n",
    "print(\"Always implement proper security measures for production ML systems.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
