{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef48374d",
   "metadata": {},
   "source": [
    "# AI Model Extraction Simulator\n",
    "## Makine Ã–ÄŸrenimi Modeli Ã‡alma SimÃ¼latÃ¶rÃ¼\n",
    "\n",
    "Bu notebook, makine Ã¶ÄŸrenimi modellerinin siyah kutu (black-box) saldÄ±rÄ±larla nasÄ±l Ã§alÄ±nabileceÄŸini simÃ¼le eder.\n",
    "\n",
    "âš ï¸ **Etik UyarÄ±**: Bu araÃ§ yalnÄ±zca eÄŸitim ve gÃ¼venlik araÅŸtÄ±rmasÄ± amaÃ§lÄ±dÄ±r. GerÃ§ek sistemlere karÅŸÄ± izinsiz kullanÄ±mÄ± yasaktÄ±r.\n",
    "\n",
    "## Ã‡alÄ±ÅŸma Prensibi\n",
    "```\n",
    "SaldÄ±rgan â†’ API SorgularÄ± â†’ Kurban Model â†’ YanÄ±tlar â†’ Transfer Ã–ÄŸrenme â†’ Klon Model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e23eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerekli kÃ¼tÃ¼phaneleri import et\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Proje kÃ¶k dizinini ekle\n",
    "project_root = Path.cwd().parent if 'examples' in str(Path.cwd()) else Path.cwd()\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Proje modÃ¼lleri\n",
    "from src.victim_model.victim_model import VictimModel, VictimModelAPI\n",
    "from src.attacker.extraction_strategies import (\n",
    "    RandomQueryStrategy, ActiveLearningStrategy, AdversarialQueryStrategy,\n",
    "    ModelExtractor\n",
    ")\n",
    "from src.clone_model.clone_model import CloneModel\n",
    "from src.utils.utils import (\n",
    "    get_device, set_random_seeds, calculate_model_similarity,\n",
    "    evaluate_model_performance, count_parameters\n",
    ")\n",
    "\n",
    "# Ayarlar\n",
    "plt.style.use('seaborn-v0_8')\n",
    "device = get_device()\n",
    "set_random_seeds(42)\n",
    "\n",
    "print(f\"ğŸš€ AI Model Extraction Simulator\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d303005",
   "metadata": {},
   "source": [
    "## 1. Kurban Model OluÅŸturma\n",
    "\n",
    "Ä°lk olarak, Ã§almaya Ã§alÄ±ÅŸacaÄŸÄ±mÄ±z kurban modeli oluÅŸturalÄ±m. Bu model gerÃ§ek dÃ¼nyada korumalÄ± bir API arkasÄ±nda olacaktÄ±r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008412e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurban modeli oluÅŸtur\n",
    "print(\"ğŸ“¦ Creating victim model...\")\n",
    "victim_model = VictimModel(\n",
    "    model_type=\"resnet18\",\n",
    "    num_classes=10,  # CIFAR-10 iÃ§in\n",
    "    pretrained=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# API wrapper oluÅŸtur\n",
    "victim_api = VictimModelAPI(victim_model, rate_limit=None)\n",
    "\n",
    "# Model bilgilerini gÃ¶ster\n",
    "param_count = count_parameters(victim_model.model)\n",
    "print(f\"âœ… Victim model created\")\n",
    "print(f\"ğŸ“Š Parameters: {param_count:,}\")\n",
    "print(f\"ğŸ“Š Model type: {victim_model.model_type}\")\n",
    "print(f\"ğŸ“Š Classes: {victim_model.num_classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0319cffe",
   "metadata": {},
   "source": [
    "## 2. Kurban Modeli Test Etme\n",
    "\n",
    "Kurban modelinin Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a696eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verisi oluÅŸtur\n",
    "test_input = torch.randn(5, 3, 32, 32)  # 5 rastgele gÃ¶rÃ¼ntÃ¼\n",
    "\n",
    "# Kurban modeli sorgula\n",
    "victim_response = victim_model.query(test_input, return_logits=True)\n",
    "\n",
    "print(\"ğŸ§ª Victim model test:\")\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Predictions: {victim_response['predictions']}\")\n",
    "print(f\"Confidence scores: {victim_response['confidence']}\")\n",
    "print(f\"Query count: {victim_model.query_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6a56de",
   "metadata": {},
   "source": [
    "## 3. FarklÄ± SaldÄ±rÄ± Stratejileri\n",
    "\n",
    "Åimdi farklÄ± sorgulama stratejilerini test edelim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b81877",
   "metadata": {},
   "source": [
    "### 3.1 Rastgele Sorgulama Stratejisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c9c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rastgele sorgulama stratejisi\n",
    "print(\"ğŸ² Testing Random Query Strategy\")\n",
    "\n",
    "random_strategy = RandomQueryStrategy(\n",
    "    data_distribution=\"uniform\",\n",
    "    input_shape=(3, 32, 32)\n",
    ")\n",
    "\n",
    "# Ã–rnek sorgular oluÅŸtur\n",
    "random_queries = random_strategy.select_queries(budget=100)\n",
    "print(f\"Generated {len(random_queries)} random queries\")\n",
    "print(f\"Query shape: {random_queries.shape}\")\n",
    "print(f\"Value range: [{random_queries.min():.3f}, {random_queries.max():.3f}]\")\n",
    "\n",
    "# Ä°lk birkaÃ§ sorguyu gÃ¶rselleÅŸtir\n",
    "fig, axes = plt.subplots(1, 4, figsize=(12, 3))\n",
    "for i in range(4):\n",
    "    # Channels first'ten channels last'e Ã§evir\n",
    "    img = random_queries[i].transpose(1, 2, 0)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f\"Random Query {i+1}\")\n",
    "    axes[i].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992829a3",
   "metadata": {},
   "source": [
    "### 3.2 Aktif Ã–ÄŸrenme Stratejisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745302f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktif Ã¶ÄŸrenme stratejisi\n",
    "print(\"ğŸ§  Testing Active Learning Strategy\")\n",
    "\n",
    "active_strategy = ActiveLearningStrategy(\n",
    "    initial_pool_size=500,\n",
    "    uncertainty_method=\"entropy\"\n",
    ")\n",
    "\n",
    "# Ä°lk sorgular (clone model olmadan)\n",
    "active_queries = active_strategy.select_queries(budget=50)\n",
    "print(f\"Generated {len(active_queries)} active learning queries\")\n",
    "print(f\"Strategy uses uncertainty-based selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8810c798",
   "metadata": {},
   "source": [
    "## 4. Model Ã‡Ä±karma SÃ¼reci\n",
    "\n",
    "Åimdi gerÃ§ek model Ã§Ä±karma sÃ¼recini baÅŸlatalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a47381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model extractor oluÅŸtur\n",
    "print(\"ğŸ”“ Setting up model extractor\")\n",
    "\n",
    "# Rastgele strateji ile baÅŸla (daha hÄ±zlÄ± demo iÃ§in)\n",
    "extractor = ModelExtractor(\n",
    "    query_strategy=random_strategy,\n",
    "    victim_api=victim_api,\n",
    "    query_budget=2000  # KÃ¼Ã§Ã¼k budget (notebook iÃ§in)\n",
    ")\n",
    "\n",
    "print(f\"âœ… Extractor ready with budget: {extractor.query_budget:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b86d9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bilgi Ã§Ä±karma\n",
    "print(\"ğŸ•³ï¸ Extracting knowledge from victim model...\")\n",
    "\n",
    "stolen_queries, stolen_responses = extractor.extract_knowledge(batch_size=64)\n",
    "\n",
    "# Ä°statistikleri gÃ¶ster\n",
    "extraction_stats = extractor.get_extraction_statistics()\n",
    "print(f\"\\nğŸ“Š Extraction Statistics:\")\n",
    "for key, value in extraction_stats.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nâœ… Collected {len(stolen_queries):,} query-response pairs\")\n",
    "print(f\"ğŸ“Š Data shape: {stolen_queries.shape} â†’ {stolen_responses.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845d9786",
   "metadata": {},
   "source": [
    "## 5. Klon Model OluÅŸturma ve EÄŸitimi\n",
    "\n",
    "Ã‡alÄ±nan verilerle klon modeli eÄŸitelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72264096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klon model oluÅŸtur\n",
    "print(\"ğŸ¤– Creating clone model\")\n",
    "\n",
    "clone_model = CloneModel(\n",
    "    architecture=\"simple_cnn\",  # Daha basit mimari\n",
    "    num_classes=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "clone_params = count_parameters(clone_model.model)\n",
    "print(f\"âœ… Clone model created\")\n",
    "print(f\"ğŸ“Š Parameters: {clone_params:,}\")\n",
    "print(f\"ğŸ“Š Architecture: {clone_model.architecture}\")\n",
    "print(f\"ğŸ“Š Victim vs Clone ratio: {clone_params/param_count:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba7f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Klon model eÄŸitimi\n",
    "print(\"ğŸ“ Training clone model with stolen data...\")\n",
    "\n",
    "training_results = clone_model.train_with_stolen_data(\n",
    "    stolen_queries=stolen_queries,\n",
    "    stolen_labels=stolen_responses,\n",
    "    epochs=30,\n",
    "    learning_rate=0.001,\n",
    "    batch_size=64,\n",
    "    temperature=3.0\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Training completed!\")\n",
    "print(f\"ğŸ“ˆ Final loss: {training_results['final_loss']:.4f}\")\n",
    "print(f\"ğŸ“ˆ Final accuracy: {training_results['final_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf49893",
   "metadata": {},
   "source": [
    "## 6. EÄŸitim GÃ¶rselleÅŸtirmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33480257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EÄŸitim geÃ§miÅŸini gÃ¶rselleÅŸtir\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss grafiÄŸi\n",
    "axes[0].plot(training_results['training_losses'])\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy grafiÄŸi\n",
    "axes[1].plot(training_results['training_accuracies'])\n",
    "axes[1].set_title('Training Accuracy')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea460094",
   "metadata": {},
   "source": [
    "## 7. Model DeÄŸerlendirmesi ve KarÅŸÄ±laÅŸtÄ±rma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e8d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test verisi oluÅŸtur\n",
    "print(\"ğŸ§ª Evaluating models...\")\n",
    "\n",
    "test_size = 500\n",
    "test_queries = np.random.uniform(0, 1, (test_size, 3, 32, 32)).astype(np.float32)\n",
    "test_tensor = torch.from_numpy(test_queries)\n",
    "\n",
    "# Her iki modelden tahmin al\n",
    "print(\"Getting predictions from victim model...\")\n",
    "victim_predictions = victim_model.query(test_tensor)\n",
    "\n",
    "print(\"Getting predictions from clone model...\")\n",
    "clone_predictions = clone_model.predict(test_tensor)\n",
    "\n",
    "# Benzerlik metriklerini hesapla\n",
    "similarity_metrics = calculate_model_similarity(\n",
    "    victim_predictions['probabilities'], \n",
    "    clone_predictions['probabilities']\n",
    ")\n",
    "\n",
    "print(f\"\\nğŸ“Š Model Similarity Metrics:\")\n",
    "for key, value in similarity_metrics.items():\n",
    "    print(f\"  {key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78c8a5",
   "metadata": {},
   "source": [
    "## 8. DetaylÄ± Analiz ve GÃ¶rselleÅŸtirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3998386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tahmin daÄŸÄ±lÄ±mlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±r\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Fidelity analizi\n",
    "victim_pred_labels = victim_predictions['predictions']\n",
    "clone_pred_labels = clone_predictions['predictions']\n",
    "agreement = victim_pred_labels == clone_pred_labels\n",
    "\n",
    "axes[0, 0].hist([victim_pred_labels, clone_pred_labels], bins=10, alpha=0.7, \n",
    "                label=['Victim', 'Clone'])\n",
    "axes[0, 0].set_title('Prediction Distribution')\n",
    "axes[0, 0].set_xlabel('Class')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Agreement analizi\n",
    "axes[0, 1].pie([agreement.sum(), (~agreement).sum()], \n",
    "               labels=['Agreement', 'Disagreement'],\n",
    "               autopct='%1.1f%%',\n",
    "               colors=['lightgreen', 'lightcoral'])\n",
    "axes[0, 1].set_title(f'Model Agreement (Fidelity: {similarity_metrics[\"fidelity\"]:.2%})')\n",
    "\n",
    "# Confidence karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "victim_conf = victim_predictions['confidence']\n",
    "clone_conf = clone_predictions['probabilities'].max(axis=1)\n",
    "\n",
    "axes[1, 0].scatter(victim_conf, clone_conf, alpha=0.5)\n",
    "axes[1, 0].plot([0, 1], [0, 1], 'r--', alpha=0.8)\n",
    "axes[1, 0].set_xlabel('Victim Confidence')\n",
    "axes[1, 0].set_ylabel('Clone Confidence')\n",
    "axes[1, 0].set_title('Confidence Correlation')\n",
    "axes[1, 0].grid(True)\n",
    "\n",
    "# Query efficiency\n",
    "query_efficiency = similarity_metrics['fidelity'] / extractor.query_count * 1000\n",
    "metrics_data = {\n",
    "    'Fidelity': similarity_metrics['fidelity'],\n",
    "    'Cosine Sim': similarity_metrics['cosine_similarity'],\n",
    "    'Query Eff.\\n(Ã—1000)': query_efficiency\n",
    "}\n",
    "\n",
    "bars = axes[1, 1].bar(metrics_data.keys(), metrics_data.values(), \n",
    "                      color=['skyblue', 'lightgreen', 'orange'])\n",
    "axes[1, 1].set_title('Performance Metrics')\n",
    "axes[1, 1].set_ylabel('Score')\n",
    "\n",
    "# Bar deÄŸerlerini ekle\n",
    "for bar, value in zip(bars, metrics_data.values()):\n",
    "    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ffde10",
   "metadata": {},
   "source": [
    "## 9. FarklÄ± Stratejilerin KarÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "\n",
    "Åimdi farklÄ± sorgulama stratejilerinin performansÄ±nÄ± karÅŸÄ±laÅŸtÄ±ralÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9af196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FarklÄ± stratejileri test et\n",
    "def test_strategy(strategy_name, strategy, budget=1000):\n",
    "    \"\"\"Bir stratejiyi test et\"\"\"\n",
    "    print(f\"\\nğŸ§ª Testing {strategy_name} strategy...\")\n",
    "    \n",
    "    # Kurban model sorgularÄ±nÄ± sÄ±fÄ±rla\n",
    "    victim_model.reset_query_log()\n",
    "    \n",
    "    # Extractor oluÅŸtur\n",
    "    extractor = ModelExtractor(\n",
    "        query_strategy=strategy,\n",
    "        victim_api=victim_api,\n",
    "        query_budget=budget\n",
    "    )\n",
    "    \n",
    "    # Bilgi Ã§Ä±kar\n",
    "    queries, responses = extractor.extract_knowledge(batch_size=32)\n",
    "    \n",
    "    # Basit clone model eÄŸit\n",
    "    clone = CloneModel(\"lightweight\", 10, device)\n",
    "    training_results = clone.train_with_stolen_data(\n",
    "        queries, responses, epochs=15, learning_rate=0.01\n",
    "    )\n",
    "    \n",
    "    # Test et\n",
    "    test_inputs = torch.randn(200, 3, 32, 32)\n",
    "    victim_out = victim_model.query(test_inputs)['probabilities']\n",
    "    clone_out = clone.predict(test_inputs)['probabilities']\n",
    "    \n",
    "    similarity = calculate_model_similarity(victim_out, clone_out)\n",
    "    \n",
    "    return {\n",
    "        'fidelity': similarity['fidelity'],\n",
    "        'queries_used': extractor.query_count,\n",
    "        'final_loss': training_results['final_loss'],\n",
    "        'query_efficiency': similarity['fidelity'] / extractor.query_count * 1000\n",
    "    }\n",
    "\n",
    "# Stratejileri test et\n",
    "strategies = {\n",
    "    'Random (Uniform)': RandomQueryStrategy(\"uniform\", (3, 32, 32)),\n",
    "    'Random (Normal)': RandomQueryStrategy(\"normal\", (3, 32, 32)),\n",
    "    'Active Learning': ActiveLearningStrategy(500, \"entropy\")\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, strategy in strategies.items():\n",
    "    results[name] = test_strategy(name, strategy, budget=800)\n",
    "\n",
    "print(\"\\nğŸ“Š Strategy Comparison Results:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    for metric, value in result.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5c4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strateji karÅŸÄ±laÅŸtÄ±rmasÄ± gÃ¶rselleÅŸtirmesi\n",
    "metrics = ['fidelity', 'query_efficiency', 'final_loss']\n",
    "strategy_names = list(results.keys())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [results[name][metric] for name in strategy_names]\n",
    "    \n",
    "    bars = axes[i].bar(strategy_names, values, color=['skyblue', 'lightgreen', 'orange'])\n",
    "    axes[i].set_title(f'{metric.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_ylabel('Score' if metric != 'final_loss' else 'Loss')\n",
    "    \n",
    "    # DeÄŸerleri bar Ã¼zerine yaz\n",
    "    for bar, value in zip(bars, values):\n",
    "        axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(values)*0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    # X eksenindeki isimleri dÃ¶ndÃ¼r\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637088f",
   "metadata": {},
   "source": [
    "## 10. GÃ¼venlik Ä°mplications ve Savunma YÃ¶ntemleri\n",
    "\n",
    "Bu bÃ¶lÃ¼mde model Ã§alma saldÄ±rÄ±larÄ±na karÅŸÄ± savunma yÃ¶ntemlerini tartÄ±ÅŸalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e04e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savunma yÃ¶ntemlerini simÃ¼le et\n",
    "def test_defense_mechanism(defense_name, defense_func):\n",
    "    \"\"\"Savunma mekanizmasÄ± test et\"\"\"\n",
    "    print(f\"\\nğŸ›¡ï¸ Testing {defense_name}...\")\n",
    "    \n",
    "    # SavunmalÄ± kurban model oluÅŸtur\n",
    "    defended_model = VictimModel(\"resnet18\", 10, True, device)\n",
    "    \n",
    "    # Savunma fonksiyonunu uygula\n",
    "    defended_api = defense_func(defended_model)\n",
    "    \n",
    "    # SaldÄ±rÄ±yÄ± dene\n",
    "    extractor = ModelExtractor(\n",
    "        RandomQueryStrategy(\"uniform\", (3, 32, 32)),\n",
    "        defended_api,\n",
    "        query_budget=500\n",
    "    )\n",
    "    \n",
    "    queries, responses = extractor.extract_knowledge()\n",
    "    \n",
    "    # Klon model eÄŸit\n",
    "    clone = CloneModel(\"lightweight\", 10, device)\n",
    "    clone.train_with_stolen_data(queries, responses, epochs=10)\n",
    "    \n",
    "    # DeÄŸerlendir\n",
    "    test_inputs = torch.randn(100, 3, 32, 32)\n",
    "    original_out = defended_model.query(test_inputs)['probabilities']\n",
    "    clone_out = clone.predict(test_inputs)['probabilities']\n",
    "    \n",
    "    similarity = calculate_model_similarity(original_out, clone_out)\n",
    "    return similarity['fidelity']\n",
    "\n",
    "# Savunma mekanizmalarÄ±\n",
    "def rate_limiting_defense(victim_model):\n",
    "    \"\"\"Rate limiting savunmasÄ±\"\"\"\n",
    "    return VictimModelAPI(victim_model, rate_limit=100)\n",
    "\n",
    "def noise_defense(victim_model):\n",
    "    \"\"\"Noise ekleme savunmasÄ±\"\"\"\n",
    "    class NoisyAPI(VictimModelAPI):\n",
    "        def predict(self, image_data, return_probabilities=True):\n",
    "            # Tahminlere noise ekle\n",
    "            result = super().predict(image_data, return_probabilities)\n",
    "            if 'probabilities' in result:\n",
    "                probs = np.array(result['probabilities'])\n",
    "                noise = np.random.normal(0, 0.05, probs.shape)\n",
    "                noisy_probs = probs + noise\n",
    "                # Normalize et\n",
    "                noisy_probs = np.maximum(noisy_probs, 0)\n",
    "                noisy_probs = noisy_probs / noisy_probs.sum(axis=-1, keepdims=True)\n",
    "                result['probabilities'] = noisy_probs.tolist()\n",
    "            return result\n",
    "    return NoisyAPI(victim_model)\n",
    "\n",
    "# SavunmalarÄ± test et\n",
    "defenses = {\n",
    "    'No Defense': lambda vm: VictimModelAPI(vm),\n",
    "    'Rate Limiting': rate_limiting_defense,\n",
    "    'Output Noise': noise_defense\n",
    "}\n",
    "\n",
    "defense_results = {}\n",
    "for name, defense in defenses.items():\n",
    "    fidelity = test_defense_mechanism(name, defense)\n",
    "    defense_results[name] = fidelity\n",
    "    print(f\"  Fidelity: {fidelity:.4f}\")\n",
    "\n",
    "print(\"\\nğŸ›¡ï¸ Defense Effectiveness:\")\n",
    "for name, fidelity in defense_results.items():\n",
    "    print(f\"  {name}: {fidelity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Savunma etkinliÄŸi gÃ¶rselleÅŸtirmesi\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "defense_names = list(defense_results.keys())\n",
    "fidelities = list(defense_results.values())\n",
    "\n",
    "bars = plt.bar(defense_names, fidelities, color=['red', 'orange', 'green'])\n",
    "plt.title('Defense Mechanism Effectiveness\\n(Lower Fidelity = Better Defense)')\n",
    "plt.ylabel('Attack Fidelity')\n",
    "plt.xlabel('Defense Method')\n",
    "\n",
    "# DeÄŸerleri bar Ã¼zerine yaz\n",
    "for bar, value in zip(bars, fidelities):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{value:.3f}', ha='center', va='bottom')\n",
    "\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c8fc5f",
   "metadata": {},
   "source": [
    "## 11. SonuÃ§lar ve Ã–neriler\n",
    "\n",
    "### Ana Bulgular:\n",
    "\n",
    "1. **Model Extraction Feasibility**: Siyah kutu modelleri bile Ã§alÄ±nabilir\n",
    "2. **Query Efficiency**: FarklÄ± stratejiler farklÄ± verimlilik seviyeleri gÃ¶sterir\n",
    "3. **Defense Mechanisms**: Basit savunma yÃ¶ntemleri bile etkili olabilir\n",
    "\n",
    "### GÃ¼venlik Ã–nerileri:\n",
    "\n",
    "1. **Rate Limiting**: API Ã§aÄŸrÄ± limitleri koyun\n",
    "2. **Output Perturbation**: Ã‡Ä±ktÄ±lara kontrollÃ¼ noise ekleyin\n",
    "3. **Query Monitoring**: Anormal sorgu patternlerini izleyin\n",
    "4. **Differential Privacy**: Gizlilik koruyucu teknikler kullanÄ±n\n",
    "5. **Watermarking**: Model watermark'larÄ± ekleyin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311bafe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Ã¶zet\n",
    "print(\"ğŸ“‹ Experiment Summary\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ¯ Original victim model accuracy: High (pretrained)\")\n",
    "print(f\"ğŸ¤– Clone model achieved: {similarity_metrics['fidelity']:.2%} fidelity\")\n",
    "print(f\"ğŸ“Š Query budget used: {extractor.query_count:,}\")\n",
    "print(f\"âš¡ Query efficiency: {query_efficiency:.4f} (fidelity per 1000 queries)\")\n",
    "print(f\"ğŸ›¡ï¸ Defense effectiveness: Noise injection reduced fidelity by {defense_results['No Defense'] - defense_results['Output Noise']:.2%}\")\n",
    "\n",
    "print(\"\\nâš ï¸ Ethical Reminder:\")\n",
    "print(\"This simulation is for educational purposes only.\")\n",
    "print(\"Real-world model extraction attacks are illegal without permission.\")\n",
    "print(\"Always implement proper security measures for production ML systems.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
