# SECURITY AND ETHICS GUIDELINES
# GÜVENLİK VE ETİK KULLANIM REHBERİ

## ⚠️ CRITICAL WARNING / KRİTİK UYARI

This tool is designed for EDUCATIONAL and SECURITY RESEARCH purposes ONLY.

Bu araç YALNIZCA EĞİTİM ve GÜVENLİK ARAŞTIRMASI amaçlıdır.

## 🚫 PROHIBITED USES / YASAK KULLANIM

### DO NOT USE THIS TOOL FOR:
- Attacking or extracting models from real production systems without explicit permission
- Any commercial model extraction activities
- Violating terms of service of any AI/ML platforms
- Any illegal activities

### BU ARACI ŞUNLAR İÇİN KULLANMAYIN:
- İzin almadan gerçek prodüksiyon sistemlerine saldırı veya model çıkarma
- Herhangi bir ticari model çıkarma faaliyeti
- AI/ML platformlarının kullanım şartlarını ihlal etme
- Herhangi bir yasa dışı faaliyet

## ✅ ACCEPTABLE USES / KABUL EDİLEBİLİR KULLANIM

### APPROPRIATE USES:
- Educational purposes to understand ML security
- Security research on your own models
- Academic research with proper permissions
- Developing defense mechanisms against model extraction
- Understanding vulnerabilities in ML systems

### UYGUN KULLANIM:
- ML güvenliğini anlamak için eğitim amaçlı
- Kendi modellerinizde güvenlik araştırması
- Uygun izinlerle akademik araştırma
- Model çıkarma saldırılarına karşı savunma geliştirme
- ML sistemlerindeki açıkları anlama

## 🛡️ SECURITY RECOMMENDATIONS / GÜVENLİK ÖNERİLERİ

If you are a ML system operator, implement these defenses:

ML sistem operatörüyseniz, şu savunmaları uygulayın:

1. **Rate Limiting**: Implement strict API rate limits
2. **Query Monitoring**: Monitor for unusual query patterns
3. **Output Perturbation**: Add controlled noise to outputs
4. **Authentication**: Require strong authentication for API access
5. **Logging**: Log all API calls for audit purposes
6. **Differential Privacy**: Use privacy-preserving techniques
7. **Model Watermarking**: Embed watermarks in your models

## 📚 EDUCATIONAL OBJECTIVES / EĞİTİM HEDEFLERİ

This simulator helps understand:

Bu simülatör şunları anlamaya yardımcı olur:

- How black-box model extraction attacks work
- Different query strategies and their effectiveness
- The importance of API security in ML systems
- Defense mechanisms against model theft
- Knowledge distillation and transfer learning concepts

## 🏛️ LEGAL CONSIDERATIONS / HUKUKI HUSUSLAR

- Unauthorized access to computer systems is illegal in most jurisdictions
- Model extraction may violate intellectual property rights
- Always obtain proper permissions before testing on third-party systems
- Consult with legal experts for commercial use cases

## 📞 RESPONSIBLE DISCLOSURE / SORUMLU AÇIKLAMA

If you discover vulnerabilities using this tool:

Bu araçla açık keşfederseniz:

1. Do not exploit the vulnerability
2. Report it to the system owner
3. Allow reasonable time for fixes
4. Follow responsible disclosure practices

## 🤝 ACADEMIC USE / AKADEMİK KULLANIM

For academic research:

Akademik araştırma için:

- Cite this work appropriately
- Follow your institution's ethics guidelines
- Obtain IRB approval if working with human subjects
- Share findings responsibly with the community

## 📝 CITATION / ALINTI

If you use this tool in your research, please cite:

Bu aracı araştırmanızda kullanırsanız, lütfen alıntı yapın:

```
@software{model_extraction_simulator,
  title={AI Model Extraction Simulator},
  author={[Your Name]},
  year={2024},
  url={https://github.com/[your-repo]/model-stealer}
}
```

## 🆘 REPORTING MISUSE / KÖTÜYE KULLANIM BİLDİRİMİ

If you become aware of misuse of this tool, please report it to:
[Contact information]

---

By using this tool, you agree to use it responsibly and ethically.

Bu aracı kullanarak, onu sorumlu ve etik bir şekilde kullanmayı kabul edersiniz.

**Remember: With great power comes great responsibility.**
**Unutmayın: Büyük güç, büyük sorumluluk getirir.**
